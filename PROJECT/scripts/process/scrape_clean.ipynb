{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e3b1034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ayaku\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ayaku\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ayaku\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ayaku\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayaku\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\ayaku\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ayaku\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from BeautifulSoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\ayaku\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from BeautifulSoup4) (4.13.2)\n",
      "Scraping Ali Gatie depuis https://genius.com/Ali-gatie-its-you-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\Ali Gatie\\MCleandeAliGatie.txt\n",
      "Scraping We the Kings depuis https://genius.com/We-the-kings-sad-song-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\We the Kings\\MCleandeWetheKings.txt\n",
      "Scraping Eminem depuis https://genius.com/Eminem-lose-yourself-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\Eminem\\MCleandeEminem.txt\n",
      "Scraping Hozier depuis https://genius.com/Hozier-take-me-to-church-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\Hozier\\MCleandeHozier.txt\n",
      "Scraping Pharrell Williams depuis https://genius.com/Pharrell-williams-happy-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\Pharrell Williams\\MCleandePharrellWilliams.txt\n",
      "Scraping OneRepublic depuis https://genius.com/Onerepublic-counting-stars-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\OneRepublic\\MCleandeOneRepublic.txt\n",
      "Scraping Miley Cyrus depuis https://genius.com/Miley-cyrus-wrecking-ball-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\Miley Cyrus\\MCleandeMileyCyrus.txt\n",
      "Scraping Justin Timberlake depuis https://genius.com/Justin-timberlake-cant-stop-the-feeling-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\Justin Timberlake\\MCleandeJustinTimberlake.txt\n",
      "Scraping Ed Sheeran depuis https://genius.com/Ed-sheeran-perfect-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\Ed Sheeran\\MCleandeEdSheeran.txt\n",
      "Scraping Nicky Youre depuis https://genius.com/Nicky-youre-and-dazy-sunroof-lyrics...\n",
      " C'est good pour C:\\Users\\AyaKu\\PROJECT\\data\\clean\\Nicky Youre\\MCleandeNickyYoure.txt\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install BeautifulSoup4\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "#Définition des Urls \n",
    "urls={ \"Ali Gatie\" : \"https://genius.com/Ali-gatie-its-you-lyrics\",\n",
    "       \"We the Kings\" : \"https://genius.com/We-the-kings-sad-song-lyrics\",\n",
    "       \"Eminem\" : \"https://genius.com/Eminem-lose-yourself-lyrics\",\n",
    "       \"Hozier\" : \"https://genius.com/Hozier-take-me-to-church-lyrics\",\n",
    "       \"Pharrell Williams\" : \"https://genius.com/Pharrell-williams-happy-lyrics\",\n",
    "       \"OneRepublic\" : \"https://genius.com/Onerepublic-counting-stars-lyrics\",\n",
    "       \"Miley Cyrus\" : \"https://genius.com/Miley-cyrus-wrecking-ball-lyrics\",\n",
    "       \"Justin Timberlake\" : \"https://genius.com/Justin-timberlake-cant-stop-the-feeling-lyrics\",\n",
    "       \"Ed Sheeran\" : \"https://genius.com/Ed-sheeran-perfect-lyrics\",\n",
    "       \"Nicky Youre\" : \"https://genius.com/Nicky-youre-and-dazy-sunroof-lyrics\"\n",
    "}\n",
    "\n",
    "#J'indique le chemin et si cela n'existe pas il va me le créer\n",
    "base_path = Path.home()/ \"PROJECT\" / \"data\" / \"clean\" \n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "#Parcours les paires de nom et url et fais du scraping\n",
    "for name, url in urls.items():\n",
    "    print(f\"Scraping {name} depuis {url}...\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Erreur {response.status_code} pour {url}\")\n",
    "            continue\n",
    "\n",
    "        #Parse le contenu HTML\n",
    "        soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "        \n",
    "        #Récupération des div avec les paroles\n",
    "        containers = soup.find_all(\"div\", class_=lambda x: x and \"Lyrics__Container\" in x)\n",
    "        \n",
    "        #Nettoie le corpus, decoupe en ligne selon et saut de ligne et les mots reccurents\n",
    "        ligne = []\n",
    "        for div in containers:\n",
    "            for line in div.get_text(separator=\"\\n\").split(\"\\n\"):\n",
    "                if len(line.split()) >=3 and not any(x in line.lower() for x in [\"lyrics\", \"read more\", \"translations\", \"contributors\"]):\n",
    "                    ligne.append(line)\n",
    "\n",
    "\n",
    "        texte = \"\\n\".join(ligne) \n",
    "\n",
    "        #Supprime tout ce qui est entre crochets\n",
    "        texte = re.sub(r\"\\[.*?\\]\", \"\", texte)\n",
    "        #Remplace les multiples sauts de ligne consécutifs\n",
    "        texte = re.sub(r\"\\n{2,}\", \"\\n\\n\", texte).strip()\n",
    "\n",
    "        #Cherche à nouveau une occ entre crochets\n",
    "        match = re.search(r\"\\[.*?\\]\", texte)\n",
    "        if match:\n",
    "            texte = texte[match.start():].lstrip(\"\\n \")\n",
    "\n",
    "        #Coupe le texte en enlevant les espaces\n",
    "        texte = texte.strip()         \n",
    "\n",
    "        #Dictionnaire pour enlever le nbr de phrase nécessaire \n",
    "        lines_r = {\n",
    "            \"Eminem\": 2,\n",
    "            \"Hozier\": 2,\n",
    "            \"Pharrell Williams\": 2,\n",
    "            \"Nicky Youre\": 0,\n",
    "            \"We the Kings\": 0\n",
    "        }\n",
    "\n",
    "        #Pour le reste juste 1 phrase\n",
    "        n = lines_r.get(name, 1)\n",
    "\n",
    "        #Coupe le ligne en texte\n",
    "        lignes= texte.split('\\n')\n",
    "        if len(lignes)> n:\n",
    "            texte = '\\n'.join(lignes[n:])\n",
    "\n",
    "        if not texte:\n",
    "            print(f\"Aucune Parole\")\n",
    "            continue\n",
    "\n",
    "        #Création du dossier\n",
    "        namedir = base_path / name\n",
    "        namedir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        #Nettoyage du nom sans espace\n",
    "        artistname = name.replace(\" \",\"\")\n",
    "        filename = f\"MCleande{artistname}.txt\"\n",
    "        filepath = namedir / filename\n",
    "\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(texte)\n",
    "\n",
    "        print(f\" C'est good pour {filepath}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur : {e}\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
